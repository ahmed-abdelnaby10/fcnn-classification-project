{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1875fdc5",
   "metadata": {},
   "source": [
    "# 03_hyperparameter_tuning (Diabetes)\n",
    "> Hyperparameters: `learning_rate`, `batch_size`, `hidden_layers`, `units`, `dropout`, `activation`, `optimizer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, itertools, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "DATA = Path('data/processed')\n",
    "train = pd.read_csv(DATA/'train.csv')\n",
    "val   = pd.read_csv(DATA/'val.csv')\n",
    "test  = pd.read_csv(DATA/'test.csv')\n",
    "\n",
    "X_train, y_train = train.drop(columns=['target']).values, train['target'].values\n",
    "X_val,   y_val   = val.drop(columns=['target']).values,   val['target'].values\n",
    "X_test,  y_test  = test.drop(columns=['target']).values,  test['target'].values\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "def make_optimizer(name, lr):\n",
    "    if name=='adam':   return Adam(lr)\n",
    "    if name=='sgd':    return SGD(learning_rate=lr, momentum=0.9, nesterov=True)\n",
    "    if name=='rmsprop':return RMSprop(learning_rate=lr)\n",
    "    raise ValueError(name)\n",
    "\n",
    "def make_model(n, hidden_layers=2, units=64, activation='relu', dropout=0.3, use_bn=True, l2=1e-4):\n",
    "    m = Sequential()\n",
    "    m.add(Dense(units, activation=activation, input_shape=(n,), kernel_regularizer=regularizers.l2(l2) if l2>0 else None))\n",
    "    if use_bn: m.add(BatchNormalization())\n",
    "    if dropout>0: m.add(Dropout(dropout))\n",
    "    for _ in range(hidden_layers-1):\n",
    "        m.add(Dense(units, activation=activation, kernel_regularizer=regularizers.l2(l2) if l2>0 else None))\n",
    "        if use_bn: m.add(BatchNormalization())\n",
    "        if dropout>0: m.add(Dropout(dropout))\n",
    "    m.add(Dense(1, activation='sigmoid'))\n",
    "    return m\n",
    "\n",
    "grid = {\n",
    "    'lr':        [1e-3, 5e-4],\n",
    "    'batch':     [32, 64],\n",
    "    'layers':    [2, 3],\n",
    "    'units':     [64, 128],\n",
    "    'dropout':   [0.2, 0.4],\n",
    "    'activation':['relu', 'elu'],\n",
    "    'opt':       ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for lr, bs, L, U, dr, act, opt_name in itertools.product(\n",
    "    grid['lr'], grid['batch'], grid['layers'], grid['units'], grid['dropout'], grid['activation'], grid['opt']\n",
    "):\n",
    "    opt = make_optimizer(opt_name, lr)\n",
    "    model = make_model(n_features, hidden_layers=L, units=U, activation=act, dropout=dr, use_bn=True, l2=1e-4)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    cb = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                     epochs=120, batch_size=bs, verbose=0, callbacks=cb)\n",
    "\n",
    "    y_prob = model.predict(X_test).ravel()\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    rows.append({\n",
    "        'lr': lr, 'batch': bs, 'layers': L, 'units': U, 'dropout': dr, 'activation': act, 'optimizer': opt_name,\n",
    "        'test_acc': float(acc),\n",
    "        'best_epoch': int(np.argmin(hist.history['val_loss'])+1),\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(rows).sort_values('test_acc', ascending=False).reset_index(drop=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1cf2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "plt.figure(figsize=(10,5)); sns.barplot(data=results, x='optimizer', y='test_acc'); plt.title('Optimizer vs Acc'); plt.show()\n",
    "plt.figure(figsize=(10,5)); sns.lineplot(data=results, x='units', y='test_acc', hue='layers', marker='o'); plt.title('Units/Layers vs Acc'); plt.show()\n",
    "plt.figure(figsize=(10,5)); sns.barplot(data=results, x='batch', y='test_acc'); plt.title('Batch Size vs Acc'); plt.show()\n",
    "plt.figure(figsize=(10,5)); sns.barplot(data=results, x='activation', y='test_acc'); plt.title('Activation vs Acc'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Path('visualizations') / 'comparison_plots' / 'tuning_results_diabetes.csv'\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "results.to_csv(out, index=False)\n",
    "out, results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save tuning plots to visualizations/comparison_plots ---\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "project_root = Path(os.getcwd()).resolve()\n",
    "if project_root.name == \"notebooks\":\n",
    "    project_root = project_root.parent\n",
    "\n",
    "CMP_DIR = project_root / \"visualizations\" / \"comparison_plots\"\n",
    "CMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Re-draw compact versions that we can save\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=results, x='optimizer', y='test_acc')\n",
    "plt.title('Optimizer vs Test Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"optimizer_vs_acc.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.lineplot(data=results, x='units', y='test_acc', hue='layers', marker='o')\n",
    "plt.title('Units & Layers vs Test Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"units_layers_vs_acc.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=results, x='batch', y='test_acc')\n",
    "plt.title('Batch Size vs Test Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"batch_vs_acc.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=results, x='activation', y='test_acc')\n",
    "plt.title('Activation vs Test Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"activation_vs_acc.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved comparison plots to:\", CMP_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
